{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet+.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9d7L2WAo3Ape",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2b52454-1097-49fd-de23-6f4430056a16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = '/content/gdrive/MyDrive/week 8/Human segmentation/data/human.zip'\n",
        "!cp \"{zip_path}\" .\n",
        "!unzip -q human.zip\n",
        "!rm human.zip"
      ],
      "metadata": {
        "id": "KNA1N7Qp3bCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import random\n",
        "import imutils"
      ],
      "metadata": {
        "id": "0OBfWohN4RYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(\"/content/human data/images\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "st41xTvDXu2E",
        "outputId": "fcde3261-ee3c-4d1f-a838-a2b495686649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2667"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path_image = r\"/content/human data/images\"\n",
        "train_path_mask = r\"/content/human data/masks\"\n",
        "train_file = open(\"train.txt\", \"w\")\n",
        "val_file = open(\"val.txt\", \"w\")\n",
        "test_file = open(\"test.txt\", \"w\")\n",
        "\n",
        "count = 0 \n",
        "for image, mask in zip(os.listdir(train_path_image), os.listdir(train_path_mask)):\n",
        "   count += 1\n",
        "   image_path = os.path.join(train_path_image, image)\n",
        "   mask_path = os.path.join(train_path_mask, mask)\n",
        "\n",
        "   if count <= 1867:\n",
        "      train_file.write(image_path + \",\" + mask_path + \"\\n\")\n",
        "   elif count <= 2267:\n",
        "      val_file.write(image_path + \",\" + mask_path + \"\\n\")\n",
        "   else:\n",
        "      test_file.write(image_path + \",\" + mask_path + \"\\n\")\n",
        "train_file.close()\n",
        "val_file.close()\n",
        "test_file.close()"
      ],
      "metadata": {
        "id": "5APms-LiWnHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader():\n",
        "    \n",
        "    def __init__(self, train_path, val_path, test_path):\n",
        "        self.train_path = train_path\n",
        "        self.val_path = val_path\n",
        "        self.test_path = test_path \n",
        "        \n",
        "        self.train_doc = np.random.permutation(open(\"train.txt\").readlines())\n",
        "        self.val_doc = np.random.permutation(open(\"val.txt\").readlines()) \n",
        "        self.test_doc = np.random.permutation(open(\"test.txt\").readlines())\n",
        "        \n",
        "        self.train_num = len(self.train_doc)\n",
        "        self.val_num = len(self.val_doc)\n",
        "        self.test_num = len(self.test_doc)\n",
        "        \n",
        "    def image_property(self, image_height = 256, image_width = 256):\n",
        "        self.height = image_height\n",
        "        self.width = image_width\n",
        "        self.channel = 3\n",
        "    \n",
        "    def init_train_property(self, batch_size = 32, epochs = 100):\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        \n",
        "    def generate_data(self, doc, augment = False):\n",
        "        batch_size = self.batch_size\n",
        "        \n",
        "        while True:\n",
        "            new = np.random.permutation(doc)\n",
        "            # Số batch trong 1 epoch nó gen ra\n",
        "            num_batch = len(new) // batch_size\n",
        "            \n",
        "            for batch in range(num_batch):\n",
        "                batch_data, batch_labels = self.one_batch(new, batch, batch_size)\n",
        "                yield batch_data, batch_labels\n",
        "                \n",
        "            if(augment):\n",
        "                for batch in range(num_batch):\n",
        "                    batch_data, batch_labels = self.one_batch(new, batch, batch_size, augment = augment)\n",
        "                    yield batch_data, batch_labels\n",
        "\n",
        "            remain_image = len(new) % batch_size\n",
        "            \n",
        "            if(remain_image > 0):\n",
        "                batch_data, batch_labels = self.one_batch(new, num_batch, batch_size, remain_image)\n",
        "                yield batch_data, batch_labels\n",
        "            \n",
        "            if(augment and (remain_image > 0)):\n",
        "                batch_data, batch_labels = self.one_batch(new, num_batch, batch_size, remain_image, augment = augment)\n",
        "                yield batch_data, batch_labels\n",
        "                \n",
        "    def one_batch(self, new, batch_number, batch_size, remain_image = 0, augment = False):\n",
        "        batch_len = remain_image if remain_image else batch_size\n",
        "        \n",
        "        batch_data = np.zeros((batch_len, self.height, self.width, self.channel))\n",
        "        batch_labels = np.zeros((batch_len, self.height, self.width, 1))\n",
        "        \n",
        "        for idx in range(batch_len):\n",
        "            d = new[idx + batch_number*batch_size][:-1].split(\",\")\n",
        "            # Image\n",
        "            image = cv2.imread(d[0]).astype(np.float32)\n",
        "            image_resized = cv2.resize(image, (self.height, self.width))\n",
        "            if augment:\n",
        "                image_resized = self._random_contrast(image_resized, 0.5, 1.5)\n",
        "            batch_data[idx, :, :, 0] = image_resized[:, :, 0]/255.0\n",
        "            batch_data[idx, :, :, 1] = image_resized[:, :, 1]/255.0\n",
        "            batch_data[idx, :, :, 2] = image_resized[:, :, 2]/255.0\n",
        "\n",
        "            # Mask\n",
        "            mask = cv2.imread(d[1], 0).astype(np.float32)\n",
        "            mask = np.where(mask > 0, 1, mask)\n",
        "            mask = cv2.medianBlur(mask, 5)\n",
        "            mask_resized = cv2.resize(mask, (self.height, self.width))\n",
        "            batch_labels[idx, :, :, :] = mask_resized.reshape((self.height, self.width, 1))\n",
        "            \n",
        "        #if augment:\n",
        "            #batch_data, batch_labels = self.augment(batch_data, batch_labels)\n",
        "        #batch_data = batch_data/255.0\n",
        "\n",
        "        return (batch_data, batch_labels)\n",
        "    \n",
        "    def augment(self, batch_data, batch_labels):\n",
        "        #batch_data, batch_labels = self.random_constrast(batch_data, batch_labels, 0.5, 1.5)\n",
        "        batch_data, batch_labels = self.random_brightness(batch_data, batch_labels)\n",
        "        #batch_data, batch_labels = self.random_rotate(batch_data, batch_labels, -15, 15)\n",
        "        batch_data, batch_labels = self.random_horizontal_flip(batch_data, batch_labels)\n",
        "        batch_data, batch_labels = self.random_vertical_flip(batch_data, batch_labels)\n",
        "        return (batch_data, batch_labels)\n",
        "    \n",
        "    def _random_contrast(self, image, lower, upper):\n",
        "        contrast_factor = random.uniform(lower, upper)\n",
        "        x = image[:,:,0]\n",
        "        mean = np.mean(x)\n",
        "        image[:,:,0] = np.clip((x - mean) * contrast_factor + mean, 0, 255).astype(np.uint8)\n",
        "        x = image[:,:,1]\n",
        "        mean = np.mean(x)\n",
        "        image[:,:,1] = np.clip((x - mean) * contrast_factor + mean, 0, 255).astype(np.uint8)\n",
        "        x = image[:,:,2]\n",
        "        mean = np.mean(x)\n",
        "        image[:,:,2] = np.clip((x - mean) * contrast_factor + mean, 0, 255).astype(np.uint8)\n",
        "        return image\n",
        "\n",
        "    def random_contrast(self, batch_data, batch_labels, lower, upper):\n",
        "        for i in range(batch_data.shape[0]):\n",
        "            batch_data[i] = self._random_contrast(batch_data, lower, upper)\n",
        "        return batch_data, batch_labels\n",
        "\n",
        "    def random_rotate(self, batch_data, batch_labels, lower=-10, upper=10):\n",
        "        for i in range(batch_data.shape[0]):\n",
        "            factor = random.randint(lower, upper)\n",
        "            batch_data[i] = imutils.rotate(batch_data[i], factor)\n",
        "            batch_labels[i] = imutils.rotate(batch_labels[i], factor)\n",
        "        return batch_data, batch_labels\n",
        "\n",
        "    def random_horizontal_flip(self, batch_data, batch_labels, p=0.5):\n",
        "        a = random.randint(0, 1)\n",
        "        if a <= p:\n",
        "            batch_data = np.flip(batch_data, axis = 3)\n",
        "            batch_labels = np.flip(batch_labels, axis = 3)\n",
        "        return batch_data, batch_labels\n",
        "\n",
        "    def random_vertical_flip(self, batch_data, batch_labels, p=0.5):\n",
        "        a = random.randint(0, 1)\n",
        "        if a <= p:\n",
        "            batch_data = np.flip(batch_data, axis = 2)\n",
        "            batch_labels = np.flip(batch_labels, axis = 2)\n",
        "        return batch_data, batch_labels\n",
        "\n",
        "    def random_brightness(self, input_img, batch_labels, brightness_range = [-100, 100]):\n",
        "        brightness = np.random.ranf()*(brightness_range[1] - brightness_range[0]) + brightness_range[0]\n",
        "        if brightness != 0:\n",
        "            if brightness > 0:\n",
        "                shadow = brightness\n",
        "                highlight = 255\n",
        "            else:\n",
        "                shadow = 0\n",
        "                highlight = 255 + brightness\n",
        "            alpha_b = (highlight - shadow)/255\n",
        "            gamma_b = shadow\n",
        "            buf = cv2.addWeighted(input_img, alpha_b, input_img, 0, gamma_b)\n",
        "        else:\n",
        "            buf = input_img.copy()\n",
        "        return buf, batch_labels\n"
      ],
      "metadata": {
        "id": "5tMk2ZqdDwBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader():\n",
        "    \n",
        "    def __init__(self, train_path, val_path):\n",
        "        self.train_path = train_path\n",
        "        self.val_path = val_path\n",
        "        \n",
        "        self.train_doc = np.random.permutation(open(\"train.txt\").readlines())\n",
        "        self.val_doc = np.random.permutation(open(\"val.txt\").readlines()) \n",
        "        \n",
        "        self.train_num = len(self.train_doc)\n",
        "        self.val_num = len(self.val_doc)\n",
        "        \n",
        "    def image_property(self, image_height = 256, image_width = 256):\n",
        "        self.height = image_height\n",
        "        self.width = image_width\n",
        "        self.channel = 3\n",
        "    \n",
        "    def init_train_property(self, batch_size = 32, epochs = 100):\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        \n",
        "    def generate_data(self, doc, augment = False):\n",
        "        batch_size = self.batch_size\n",
        "        \n",
        "        while True:\n",
        "            #new = np.random.permutation(doc)\n",
        "            new = doc\n",
        "            num_batch = len(new) // batch_size\n",
        "            \n",
        "            for batch in range(num_batch):\n",
        "                batch_data, batch_labels = self.one_batch(new, batch, batch_size)\n",
        "                yield batch_data, batch_labels\n",
        "                \n",
        "            if(augment):\n",
        "                for batch in range(num_batch):\n",
        "                    batch_data, batch_labels = self.one_batch(new, batch, batch_size, augment = augment)\n",
        "                    yield batch_data, batch_labels\n",
        "\n",
        "            remain_image = len(new) % batch_size\n",
        "            \n",
        "            if(remain_image):\n",
        "                batch_data, batch_labels = self.one_batch(new, num_batch, batch_size, remain_image)\n",
        "                yield batch_data, batch_labels\n",
        "            \n",
        "            if(augment and (remain_image)):\n",
        "                batch_data, batch_labels = self.one_batch(new, num_batch, batch_size, remain_image, augment = augment)\n",
        "                yield batch_data, batch_labels\n",
        "                \n",
        "    def one_batch(self, new, batch_number, batch_size, remain_image = 0, augment = False):\n",
        "        batch_len = remain_image if remain_image else batch_size\n",
        "        \n",
        "        batch_data = np.zeros((batch_len, self.height, self.width, self.channel))\n",
        "        batch_labels = np.zeros((batch_len, self.height, self.width, 1))\n",
        "        \n",
        "        for idx in range(batch_len):\n",
        "            d = new[idx + batch_number*batch_size][:-1].split(\",\")\n",
        "            # Image\n",
        "            image = cv2.imread(d[0]).astype(np.float32)\n",
        "            image_resized = cv2.resize(image, (self.height, self.width))\n",
        "            #if augment:\n",
        "                #image_resized = self.augment1(image_resized, 0.5, 1.5)\n",
        "            batch_data[idx, :, :, 0] = image_resized[:, :, 0]/255.0*2-1\n",
        "            batch_data[idx, :, :, 1] = image_resized[:, :, 1]/255.0*2-1\n",
        "            batch_data[idx, :, :, 2] = image_resized[:, :, 2]/255.0*2-1\n",
        "\n",
        "            # Mask\n",
        "            mask = cv2.imread(d[1], 0).astype(np.float32)\n",
        "            mask = np.where(mask > 0, 1, mask)\n",
        "            mask = cv2.medianBlur(mask, 5)\n",
        "            mask_resized = cv2.resize(mask, (self.height, self.width))\n",
        "            batch_labels[idx, :, :, :] = mask_resized.reshape((self.height, self.width, 1))\n",
        "            \n",
        "        #if augment:\n",
        "            #batch_data, batch_labels = self.augment1(batch_data, batch_labels)\n",
        "        #batch_data = batch_data/255.0*2-1 \n",
        "        return (batch_data, batch_labels)\n",
        "    \n",
        "    def augment(self, batch_data, batch_labels):\n",
        "        batch_data = np.flip(batch_data, axis = 3)\n",
        "        batch_labels = np.flip(batch_labels, axis = 3)\n",
        "        return (batch_data, batch_labels)\n",
        "\n",
        "    def random_brightness(self, input_img, brightness_range = [-30, 60]):\n",
        "        brightness = np.random.ranf()*(brightness_range[1] - brightness_range[0]) + brightness_range[0]\n",
        "        if brightness != 0:\n",
        "            if brightness > 0:\n",
        "                shadow = brightness\n",
        "                highlight = 255\n",
        "            else:\n",
        "                shadow = 0\n",
        "                highlight = 255 + brightness\n",
        "            alpha_b = (highlight - shadow)/255\n",
        "            gamma_b = shadow\n",
        "            buf = cv2.addWeighted(input_img, alpha_b, input_img, 0, gamma_b)\n",
        "        else:\n",
        "            buf = input_img.copy()\n",
        "        return buf\n",
        "\n",
        "    def augment1(self, tensor, batch_labels, p = 0.6):\n",
        "        a = random.random()\n",
        "        if a < p:\n",
        "            tensor = np.flip(tensor, axis=3)\n",
        "            batch_labels = np.flip(batch_labels, axis = 3)\n",
        "        tensor = self.random_contrast(tensor, 0.5, 1.5)\n",
        "        tensor = self.random_brightness(tensor, [-100, 100])\n",
        "        return (tensor, batch_labels)\n",
        "    \n",
        "    def random_contrast(self, image, lower, upper):\n",
        "        contrast_factor = random.uniform(lower, upper)\n",
        "        x = image[:,:,0]\n",
        "        mean = np.mean(x)\n",
        "        image[:,:,0] = np.clip((x - mean) * contrast_factor + mean, 0, 255).astype(np.uint8)\n",
        "        x = image[:,:,1]\n",
        "        mean = np.mean(x)\n",
        "        image[:,:,1] = np.clip((x - mean) * contrast_factor + mean, 0, 255).astype(np.uint8)\n",
        "        x = image[:,:,2]\n",
        "        mean = np.mean(x)\n",
        "        image[:,:,2] = np.clip((x - mean) * contrast_factor + mean, 0, 255).astype(np.uint8)\n",
        "        return image"
      ],
      "metadata": {
        "id": "OPcHtTuQGG07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dice coefficient loss\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
        "    return (2.*intersection + smooth)/(K.sum(K.square(y_true),-1)+ K.sum(K.square(y_pred),-1) + smooth)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1-dice_coef(y_true, y_pred)"
      ],
      "metadata": {
        "id": "Csk42PMnDfpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_IoU(y_true, y_pred):\n",
        "    y_pred = K.argmax(y_pred)\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    y_pred = K.flatten(y_pred)\n",
        "    y_true = K.flatten(y_true)\n",
        "    intersection = K.sum(y_true * y_pred)\n",
        "    IoU = intersection / (K.sum(y_true) + K.sum(y_pred) - intersection)\n",
        "    return IoU"
      ],
      "metadata": {
        "id": "nUMwBJ-F5IpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(x, filter_out):\n",
        "\n",
        "  x = Conv2D(filter_out, kernel_size=(3, 3), padding = 'same', kernel_initializer = 'he_normal')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(\"relu\")(x)\n",
        "\n",
        "  x = Conv2D(filter_out, kernel_size=(3, 3), padding = 'same', kernel_initializer = 'he_normal')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(\"relu\")(x)\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "Zln8pgis8aYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def block(x, filter_out):\n",
        "\n",
        "  x = Conv2D(filter_out, kernel_size=(3, 3), activation = \"relu\", padding = 'same', kernel_initializer = 'he_normal')(x)\n",
        "\n",
        "  x = Conv2D(filter_out, kernel_size=(3, 3), activation = \"relu\", padding = 'same', kernel_initializer = 'he_normal')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "DRu0Jj9FqnzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def UnetPlus(input_shape = (256, 256, 3)):\n",
        "\n",
        "  inputs = Input(shape=input_shape)\n",
        "\n",
        "  x00 = block(inputs, 16)\n",
        "  p0 = MaxPooling2D((2, 2))(x00)\n",
        "\n",
        "  x10 = block(p0, 32)\n",
        "  p1 = MaxPooling2D((2, 2))(x10)\n",
        "\n",
        "  x01 = UpSampling2D((2, 2))(x10)\n",
        "  x01 = Concatenate()([x00, x01])\n",
        "  x01 = conv_block(x01, 16)\n",
        "\n",
        "  x20 = block(p1, 48)\n",
        "  p2 = MaxPooling2D((2, 2))(x20)\n",
        "\n",
        "  x11 = UpSampling2D((2, 2))(x20)\n",
        "  x11 = Concatenate()([x10, x11])\n",
        "  x11 = conv_block(x11, 32)\n",
        "\n",
        "  x02 = UpSampling2D((2, 2))(x11)\n",
        "  x02 = Concatenate()([x01, x02])\n",
        "  x02 = conv_block(x02, 16)\n",
        "\n",
        "  x30 = block(p2, 64)\n",
        "\n",
        "  x21 = UpSampling2D((2, 2))(x30)\n",
        "  x21 = Concatenate()([x21, x20])\n",
        "  x21 = conv_block(x21, 48)\n",
        "\n",
        "  x12 = UpSampling2D((2, 2))(x21)\n",
        "  x12 = Concatenate()([x12, x11])\n",
        "  x12 = conv_block(x12, 32)\n",
        "\n",
        "  x03 = UpSampling2D((2, 2))(x12)\n",
        "  x03 = Concatenate()([x02, x03])\n",
        "  x03 = conv_block(x03, 16)\n",
        "  outputs = Conv2D(2, (1, 1), padding=\"same\", activation = \"softmax\")(x03)\n",
        "\n",
        "  model = Model(inputs = inputs, outputs = outputs)\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "_3IDBRE55Rhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Unet(input_shape =(256, 256, 3)):\n",
        "\n",
        "  inputs = Input(shape=input_shape)\n",
        "\n",
        "  x0 = block(inputs, 16)\n",
        "  x = MaxPooling2D((2, 2))(x0)\n",
        "\n",
        "  x1 = block(x, 32)\n",
        "  x = MaxPooling2D((2, 2))(x1)\n",
        "\n",
        "  x2 = block(x, 48)\n",
        "  x = MaxPooling2D((2, 2))(x2)\n",
        "\n",
        "  x3 = block(x, 64)\n",
        "  \n",
        "  x = UpSampling2D((2, 2))(x3)\n",
        "  x = Concatenate()([x2, x])\n",
        "  x = conv_block(x, 48)\n",
        "\n",
        "  x = UpSampling2D((2, 2))(x)\n",
        "  x = Concatenate()([x1, x])\n",
        "  x = conv_block(x, 32)\n",
        "\n",
        "  x = UpSampling2D((2, 2))(x)\n",
        "  x = Concatenate()([x0, x])\n",
        "  x = conv_block(x, 16)\n",
        "\n",
        "  outputs = Conv2D(2, (1, 1), padding=\"same\", activation = \"softmax\")(x)\n",
        "  model = Model(inputs = inputs, outputs = outputs)\n",
        "  model.summary()\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "fFDXczjLrO0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UnetPlus()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LziBfVdY68O",
        "outputId": "4be454fa-fab2-4327-8cd4-8ce036a6ad70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 256, 256, 16  448         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 256, 256, 16  2320        ['conv2d[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 256, 256, 16  64         ['conv2d_1[0][0]']               \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 128, 128, 16  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 128, 128, 32  4640        ['max_pooling2d[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 128, 128, 32  9248        ['conv2d_2[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 128, 128, 32  128        ['conv2d_3[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 32)  0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 64, 64, 48)   13872       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 64, 64, 48)   20784       ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 64, 64, 48)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 48)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 32, 32, 64)   27712       ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 32, 32, 64)   36928       ['conv2d_12[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_13[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 64)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 48  0          ['batch_normalization_4[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 64, 64, 112)  0           ['up_sampling2d_3[0][0]',        \n",
            "                                                                  'batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 256, 256, 32  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 128, 128, 80  0           ['batch_normalization_1[0][0]',  \n",
            "                                )                                 'up_sampling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 64, 64, 48)   48432       ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 256, 256, 48  0           ['batch_normalization[0][0]',    \n",
            "                                )                                 'up_sampling2d[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 128, 128, 32  23072       ['concatenate_1[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 64, 64, 48)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 256, 256, 16  6928        ['concatenate[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 128, 128, 32  128        ['conv2d_8[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 64, 64, 48)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 256, 256, 16  64         ['conv2d_4[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 128, 128, 32  0           ['batch_normalization_5[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 64, 64, 48)   20784       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 256, 256, 16  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 128, 128, 32  9248        ['activation_2[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 64, 64, 48)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 256, 256, 16  2320        ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 128, 128, 32  128        ['conv2d_9[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 64, 64, 48)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 256, 256, 16  64         ['conv2d_5[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 128, 128, 32  0           ['batch_normalization_6[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_4 (UpSampling2D)  (None, 128, 128, 48  0          ['activation_7[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 256, 256, 16  0           ['batch_normalization_3[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 32  0          ['activation_3[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 128, 128, 80  0           ['up_sampling2d_4[0][0]',        \n",
            "                                )                                 'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 256, 256, 48  0           ['activation_1[0][0]',           \n",
            "                                )                                 'up_sampling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 128, 128, 32  23072       ['concatenate_4[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 256, 256, 16  6928        ['concatenate_2[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 128, 128, 32  128        ['conv2d_16[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 256, 256, 16  64         ['conv2d_10[0][0]']              \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 128, 128, 32  0           ['batch_normalization_12[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 256, 256, 16  0           ['batch_normalization_7[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 128, 128, 32  9248        ['activation_8[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 256, 256, 16  2320        ['activation_4[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 128, 128, 32  128        ['conv2d_17[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 256, 256, 16  64         ['conv2d_11[0][0]']              \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 128, 128, 32  0           ['batch_normalization_13[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 256, 256, 16  0           ['batch_normalization_8[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_5 (UpSampling2D)  (None, 256, 256, 32  0          ['activation_9[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 256, 256, 48  0           ['activation_5[0][0]',           \n",
            "                                )                                 'up_sampling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 256, 256, 16  6928        ['concatenate_5[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 256, 256, 16  64         ['conv2d_18[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 256, 256, 16  0           ['batch_normalization_14[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 256, 256, 16  2320        ['activation_10[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 256, 256, 16  64         ['conv2d_19[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 256, 256, 16  0           ['batch_normalization_15[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 256, 256, 2)  34          ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 279,506\n",
            "Trainable params: 278,546\n",
            "Non-trainable params: 960\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = r\"E:\\train\"\n",
        "val_dir = r\"E:\\val\"\n",
        "data = DataLoader(train_dir, val_dir)\n",
        "data.image_property()\n",
        "data.init_train_property(batch_size =32, epochs = 300)\n",
        "print(data.train_num, \" \", data.val_num)\n",
        "train_gen = data.generate_data(data.train_doc, augment = True)\n",
        "val_gen = data.generate_data(data.val_doc, augment = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El4XIHJRY8m0",
        "outputId": "e2a72dbd-3681-4696-fa08-6196359d889b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1867   400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.001), loss=SparseCategoricalCrossentropy(), metrics=[my_IoU])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(r\"/content/gdrive/MyDrive/week 8/Human segmentation/best model/Unet+_{val_loss: .4f}_{val_my_IoU: .5f}.hdf5\", save_best_only=True, save_weights_only= True, monitor = \"val_my_IoU\", mode = \"max\"),\n",
        "    ReduceLROnPlateau(monitor='val_loss', patience=20, verbose=1, factor=0.1, min_lr=0.0000001)\n",
        "]"
      ],
      "metadata": {
        "id": "-y8_YhTcZlLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_gen = data.generate_data(data.train_doc, augment = True)\n",
        "#val_gen = data.generate_data(data.val_doc, augment = False)\n",
        "\n",
        "steps_per_epoch = 0\n",
        "validation_steps = 0\n",
        "if ((2*data.train_num) % data.batch_size) == 0:\n",
        "    steps_per_epoch = int((2*data.train_num) / data.batch_size)\n",
        "else:\n",
        "    steps_per_epoch = ((2*data.train_num) // data.batch_size) + 1\n",
        "\n",
        "if ((data.val_num) % data.batch_size) == 0:\n",
        "    validation_steps = int((data.val_num) / data.batch_size)\n",
        "else:\n",
        "    validation_steps = ((data.val_num) // data.batch_size) + 1\n",
        "#print(steps_per_epoch, \" \", validation_steps)\n",
        "\n",
        "history=model.fit(train_gen, epochs=data.epochs, steps_per_epoch= steps_per_epoch, validation_steps= validation_steps, callbacks=callbacks,\n",
        "                           validation_data=val_gen, batch_size = data.batch_size, initial_epoch=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOCILlxXbMSV",
        "outputId": "0f7d2bde-b440-48da-b4f6-3de79dbcd1d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "117/117 [==============================] - 525s 4s/step - loss: 0.5347 - my_IoU: 0.4221 - val_loss: 0.5091 - val_my_IoU: 0.1850 - lr: 0.0010\n",
            "Epoch 2/300\n",
            "117/117 [==============================] - 511s 4s/step - loss: 0.3957 - my_IoU: 0.5411 - val_loss: 0.6270 - val_my_IoU: 0.0536 - lr: 0.0010\n",
            "Epoch 3/300\n",
            "117/117 [==============================] - 513s 4s/step - loss: 0.3459 - my_IoU: 0.6012 - val_loss: 0.5437 - val_my_IoU: 0.2834 - lr: 0.0010\n",
            "Epoch 4/300\n",
            " 78/117 [===================>..........] - ETA: 2:25 - loss: 0.3266 - my_IoU: 0.6250"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RtbxKkhweJkO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}